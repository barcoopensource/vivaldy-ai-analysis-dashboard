{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Data for this study was obtained from the BCSC: http://bcsc-research.org/.\"\n",
    "\"\"\"\n",
    "The following must be cited when using this dataset:\n",
    "\"Data collection and sharing was supported by the National Cancer Institute-funded Breast Cancer Surveillance Consortium (HHSN261201100031C). You can learn more about the BCSC at: http://www.bcsc-research.org/.\"\n",
    "\"\"\"\n",
    "\n",
    "!curl \"https://www.bcsc-research.org/application/files/2815/4697/9928/risk_dataset.zip\" --output BCSC_risk_dataset.zip\n",
    "!curl \"https://www.bcsc-research.org/application/files/6315/4697/9929/risk_dataset_v2.zip\" --output BCSC_risk_dataset_v2.zip\n",
    "# NOTE: if the above fails, download the \"Risk Estimation Dataset\" from https://www.bcsc-research.org/data or https://www.bcsc-research.org/data/rfdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf BCSC_risk_dataset.zip\n",
    "!tar -xf BCSC_risk_dataset_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['menopaus', 'agegrp', 'density', 'race', 'Hispanic', 'bmi', 'agefirst', 'nrelbc', 'brstproc', 'lastmamm', 'surgmeno', 'hrt', 'invasive', 'cancer', 'training', 'count']\n",
    "df_risk = pd.DataFrame(numpy.loadtxt('risk.txt', dtype=int), columns=column_names)\n",
    "df_risk_v2 = pd.DataFrame(numpy.loadtxt('risk_rand.txt', dtype=int), columns=column_names)\n",
    "df_risk = pd.concat([df_risk, df_risk_v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid complicating the training, we limit the dataset to complete records (i.e. no blank or unknown fields, marked with the value 9)\n",
    "# Exclude column agegrp as the age is always known; and surgmeno as this can relate to premenopausal\n",
    "columns_possibly_unknown = list(df_risk.columns)\n",
    "columns_possibly_unknown.remove('agegrp')\n",
    "columns_possibly_unknown.remove('surgmeno')\n",
    "df_risk = df_risk[~(df_risk[columns_possibly_unknown]==9).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use both training and test data, and apply K-fold sharding later on.\n",
    "df_risk.drop(columns=['training'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reverse deflate according to the count column\n",
    "df_risk = df_risk.loc[df_risk.index.repeat(df_risk['count'])].reset_index(drop=True)\n",
    "df_risk = df_risk.drop(columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and target\n",
    "df_target = df_risk['cancer']\n",
    "df_data = df_risk.drop(columns=['cancer', 'invasive'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train AI network + 3. Full inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble of networks with fixed random states for reproducibility\n",
    "random_states = [1234, 2345, 3456, 4567]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* no demographic information\n",
    "* no stratification\n",
    "* data split train/validation: 75% / 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, ensemble\n",
    "import numpy as np\n",
    "\n",
    "# Create placeholder for AI output results\n",
    "df_predictions = pd.DataFrame()\n",
    "\n",
    "for model_id, random_state in enumerate(random_states):\n",
    "    print(f'model_id: {model_id}')\n",
    "    kf = model_selection.KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    rfc = ensemble.RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "    df_prediction = df_target.copy(deep=True)\n",
    "    \n",
    "    class_balancing_ratio = int(df_prediction.count() / df_prediction.sum())\n",
    "\n",
    "    # For each fold: train, predict and store results\n",
    "    for idx, (train_index, validation_index) in enumerate(kf.split(df_data)):\n",
    "\n",
    "        # class balancing; additional factor 3 to move the point on the ROC curve towards higher sensitivity\n",
    "        sample_weight = 3 * (class_balancing_ratio - 2) * df_target.iloc[train_index] + 1\n",
    "        train_index_balanced = train_index.repeat(sample_weight)\n",
    "        \n",
    "        \n",
    "        rfc.fit(df_data.iloc[train_index], df_target.iloc[train_index], sample_weight=sample_weight)\n",
    "        prediction_class = rfc.predict(df_data.iloc[validation_index])\n",
    "        prediction_score = rfc.predict_proba(df_data.iloc[validation_index])[:,1]\n",
    "        \n",
    "        # Store prediction in df_output\n",
    "        df_prediction.iloc[validation_index] = prediction_score\n",
    "        \n",
    "        # Calculate and print sensitivity and specificity for fold\n",
    "        tn, fp, fn, tp = sklearn.metrics.confusion_matrix(df_target.iloc[validation_index], prediction_class, labels=[0, 1]).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        print(f'fold {idx} - sensitivity: {sensitivity} / specificity: {specificity}')\n",
    "\n",
    "    df_predictions[f'model_{model_id}'] = df_prediction\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual model sensitivity and specificity\n",
    "for model_id, c in enumerate(df_predictions.columns):\n",
    "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(df_target, df_predictions[c] > 0.5, labels=[0, 1]).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    print(f'model {model_id} - sensitivity: {sensitivity} / specificity: {specificity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble model sensitivity and specificity\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(df_target, df_predictions.median(axis=1) > 0.5, labels=[0, 1]).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print(f'Ensemble model - sensitivity: {sensitivity} / specificity: {specificity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and export data\n",
    "df_output = df_data.copy()\n",
    "df_output['gt'] = df_target\n",
    "for c in df_predictions.columns:\n",
    "    df_output[f'prediction_{c}'] = df_predictions[c]\n",
    "df_output['malignancy_score'] = df_predictions.median(axis=1)\n",
    "df_output.index.name = 'record_id'\n",
    "\n",
    "df_output.to_csv('dataset_example_BCSC.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Config file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check config file ```settings/settings_data_slicing_pipeline_example_BCSC.py```\n",
    "\n",
    "##### Dataframe structure\n",
    "```\n",
    "'dataframe': {\n",
    "    'index': 'record_id',\n",
    "    # Additional columns to export from the original DataFrame\n",
    "    'export': [\n",
    "        'record_id',\n",
    "        'malignancy_score'\n",
    "    ],\n",
    "    'formatting': {\n",
    "        'binary_classification': {\n",
    "            'pred_label_input': 'malignancy_score',\n",
    "            'pred_label_output': 'malignancy_label_pred',\n",
    "            'gt_label_input': 'gt',\n",
    "            'gt_label_output': 'malignancy_label_gt',\n",
    "            'classification_threshold': 0.5,\n",
    "            'na_strict': False,\n",
    "            'na_fill': 'unknown',\n",
    "\n",
    "        },\n",
    "        'object_detection': {},\n",
    "        'segmentation': {},\n",
    "        'description_separator': '  '\n",
    "    }\n",
    "}\n",
    "```\n",
    "##### Slicing options\n",
    "```\n",
    "'slicing': {\n",
    "    'data_slicing_minimum_samples': 100,\n",
    "    # Format: 'column name as defined in dataframe': 'short column name to be used in the viewer'\n",
    "    'meta_data_fields_of_interest': {\n",
    "        'menopaus': 'menopause',\n",
    "        'agegrp': 'age_group',\n",
    "        'density': 'density',\n",
    "        'race': 'ethnicity',\n",
    "        'Hispanic': 'Hispanic',\n",
    "        'bmi': 'bmi',\n",
    "        'agefirst': 'age_first_child',\n",
    "        'nrelbc': 'nrelbc',\n",
    "        'brstproc': 'rstproc',\n",
    "        'lastmamm': 'lastmamm',\n",
    "        'surgmeno': 'surgmeno',\n",
    "        'hrt': 'hrt'\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "##### Additional metrics\n",
    "```\n",
    "'additional_metrics': {\n",
    "    MalignancyScore: {'probabilites_columns': 'malignancy_score'},\n",
    "    ConfidenceScore: {'probabilites_columns': list([f'prediction_model_{model_id}' for model_id in range(4)])},\n",
    "    OutlierScore: {'probabilites_columns': 'malignancy_score'}\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Categorize values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def _data_parsing_BCSC(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    import numpy as np\n",
    "    # fix incorrectly saved file if necessary\n",
    "    if 'level_0' in df.columns:\n",
    "        df = df.drop(columns='level_0')\n",
    "\n",
    "    # Rename column names to avoid spaces\n",
    "    df = df.rename(columns={c: c.replace(' ', '_') for c in df.columns})\n",
    "\n",
    "    # rename categories\n",
    "    category_labels = {\n",
    "        'menopaus': {0: 'premenopausal', 1: 'postmenopausal_or_age_>=_55'},\n",
    "        'agegrp': {1: '35-39', 2: '40-44', 3: '45-49', 4: '50-54', 5: '55-59', 6: '60-64', 7: '65-69', 8: '70-74', 9: '75-79', 10: '80-84'},\n",
    "        # 'density': {},\n",
    "        'race': {1: 'white', 2: 'Asian/Pacific_Islander', 3: 'black', 4: 'Native_American', 5: 'other/mixed'},\n",
    "        'Hispanic': {0: 'no', 1: 'yes'},\n",
    "        'bmi': {0: '[10,25[', 1: '[25,30[', 2: '[30,35[', 3: '>=35'},\n",
    "        'agefirst': {0: '<30', 1: '>=30', 2: 'Nulliparous'},\n",
    "        'nrelbc': {0: '0', 1: '1', 2: '>=2'},\n",
    "        'brstproc': {0: 'no', 1: 'yes'},\n",
    "        'lastmamm': {0: 'negative', 1: 'false_positive'},\n",
    "        'surgmeno': {0: 'no', 1: 'yes'},\n",
    "        'hrt': {0: 'no', 1: 'yes', 9: 'unknown_or_premenopausal'}\n",
    "    }\n",
    "    for c, d_rename in category_labels.items():\n",
    "        df[c] = df[c].replace(d_rename)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _subsample_BCSC(df: pd.DataFrame, frac=0.1) -> pd.DataFrame:\n",
    "    # (optional) Return subsample of the dataframe as the dataframe is large\n",
    "    return df.sample(frac=frac, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Automated analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch analysis pipeline\n",
    "from backend_launcher import run_data_slicing_experiment\n",
    "import pandas as pd\n",
    "import settings.settings_data_slicing_pipeline_example_BCSC_full as config_full\n",
    "import settings.settings_data_slicing_pipeline_example_BCSC_minimal as config_minimal\n",
    "\n",
    "# Keep the flag FULL_ANALYSIS set to False to prepare the dataframe only and use the analysis results provided with the repo.\n",
    "# Set to True to run a full analysis from scratch.\n",
    "FULL_ANALYSIS = False\n",
    "\n",
    "experiments_to_run = [\n",
    "    {\n",
    "        'config': config_minimal,\n",
    "        'df': pd.read_csv('dataset_example_BCSC.csv', low_memory=False),\n",
    "        'output_name': 'example_BCSC_minimal_fraction_0.1',\n",
    "        'optional_preprocessing_steps': [_data_parsing_BCSC, lambda x: _subsample_BCSC(x, 0.1)],\n",
    "        'degrees': [0, 1, 2, 3],\n",
    "        'stop_after_df_preparation': not FULL_ANALYSIS\n",
    "    },\n",
    "    {\n",
    "        'config': config_full,\n",
    "        'df': pd.read_csv('dataset_example_BCSC.csv', low_memory=False),\n",
    "        'output_name': 'example_BCSC_full_fraction_0.1',\n",
    "        'optional_preprocessing_steps': [_data_parsing_BCSC, lambda x: _subsample_BCSC(x, 0.1)],\n",
    "        'degrees': [0, 1, 2, 3],\n",
    "        'stop_after_df_preparation': not FULL_ANALYSIS\n",
    "    },\n",
    "    {\n",
    "        'config': config_minimal,\n",
    "        'df': pd.read_csv('dataset_example_BCSC.csv', low_memory=False),\n",
    "        'output_name': 'example_BCSC_minimal_fraction_0.5',\n",
    "        'optional_preprocessing_steps': [_data_parsing_BCSC, lambda x: _subsample_BCSC(x, 0.5)],\n",
    "        'degrees': [0, 1, 2, 3],\n",
    "        'stop_after_df_preparation': not FULL_ANALYSIS\n",
    "    },\n",
    "    {\n",
    "        'config': config_full,\n",
    "        'df': pd.read_csv('dataset_example_BCSC.csv', low_memory=False),\n",
    "        'output_name': 'example_BCSC_full_fraction_0.5',\n",
    "        'optional_preprocessing_steps': [_data_parsing_BCSC, lambda x: _subsample_BCSC(x, 0.5)],\n",
    "        'degrees': [0, 1, 2, 3],\n",
    "        'stop_after_df_preparation': not FULL_ANALYSIS\n",
    "    }\n",
    "]\n",
    "\n",
    "for experiment in experiments_to_run:\n",
    "    run_data_slicing_experiment(**experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i dashboard.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('vivaldy_dashboard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e850c2fd5fea9d09dd1bfa00a38957ce1995ecd0f7ccd96b7300b9fbad858fa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
